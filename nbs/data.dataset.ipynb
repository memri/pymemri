{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f328cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.dataset\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a2575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "from typing import List, Union, Any\n",
    "from pathlib import Path\n",
    "from pymemri.data.itembase import Item, EdgeList\n",
    "from pymemri.exporters.exporters import Query\n",
    "from pymemri.data import _central_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1901b7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f767c976",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543f6885",
   "metadata": {},
   "source": [
    "A dataset is a central item in the pod that organizes your project data and label annotations. To facilitate using `Dataset` items in your datascience workflow, the `Dataset` class contains methods to convert the data to a popular datascience format, or save a dataset to disk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2f01e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "def filter_rows(dataset: dict, filter_val=None) -> dict:\n",
    "    missing_idx = set()\n",
    "    for column in dataset.values():\n",
    "        missing_idx.update([i for i, val in enumerate(column) if val == filter_val])\n",
    "    return {\n",
    "        k: [item for i, item in enumerate(v) if i not in missing_idx]\n",
    "        for k, v in dataset.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e9a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Dataset(_central_schema.Dataset):\n",
    "    \"\"\"\n",
    "    The main Dataset class\n",
    "    \"\"\"\n",
    "    requires_client_ref = True\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._client = None\n",
    "\n",
    "    def _get_items(self):\n",
    "        if self._client is None:\n",
    "            raise ValueError(\"Dataset does not have associated PodClient.\")\n",
    "        if not len(self.entry):\n",
    "            edges = self._client.get_edges(self.id)\n",
    "            for e in self._client.get_edges(self.id):\n",
    "                self.add_edge(e[\"name\"], e[\"item\"])\n",
    "\n",
    "        return self.entry\n",
    "\n",
    "    def _get_data(self, dtype: str, columns: List[str], filter_missing: bool = True):\n",
    "        if self._client is None:\n",
    "            raise ValueError(\"Dataset does not have associated PodClient.\")\n",
    "        items = self._get_items()\n",
    "\n",
    "        query = Query(\"id\", *columns)\n",
    "        result = query.execute(self._client, items)\n",
    "        if filter_missing:\n",
    "            result = filter_rows(result, filter_val=None)\n",
    "        return query.convert_dtype(result, dtype)\n",
    "\n",
    "    def to(self, dtype: str, columns: List[str], filter_missing: bool = True):\n",
    "        \"\"\"\n",
    "        Converts Dataset to a different format.\n",
    "\n",
    "        Available formats:\n",
    "        list: a 2-dimensional list, containing one dataset entry per row\n",
    "        dict: a list of dicts, where each dict contains {column: value} for each column\n",
    "        pd: a Pandas dataframe\n",
    "\n",
    "\n",
    "        Args:\n",
    "            dtype (str): Datatype of the returned dataset\n",
    "            columns (List[str]): Column names of the dataset\n",
    "            filter_missing (bool, optional): If true, all rows that contain `None` values are omitted.\n",
    "                Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            Any: Dataset formatted according to `dtype`\n",
    "        \"\"\"\n",
    "        return self._get_data(dtype, columns, filter_missing)\n",
    "\n",
    "    def save(\n",
    "        self, path: Union[Path, str], columns: List[str], filter_missing: bool = True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Save dataset to CSV.\n",
    "        \"\"\"\n",
    "        result = self._get_data(\"pandas\", columns, filter_missing)\n",
    "        result.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6374315",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Dataset.to)\n",
    "\n",
    "show_doc(Dataset.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e11166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from pymemri.pod.client import PodClient\n",
    "from pymemri.data.schema import Account, Person, Message, CategoricalLabel, DatasetEntry\n",
    "from pymemri.data.itembase import Edge\n",
    "import random\n",
    "import tempfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959a27e7",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "To convert the data in the pod to a different format, `Dataset` implements the `Dataset.to` method. In the `columns` argument, you can define which features will be included in your dataset. A `column` is either a property of an entry in the dataset, or a property of an item connected to an entry in the dataset.\n",
    "\n",
    "The Pod uses the following schema for Dataset items. Note that the `DatasetEntry` item is always included, and the actual data can be found by traversing the `entry.data` Edge.\n",
    "\n",
    "![dataset schema](images/dataset-diagram.png)\n",
    "\n",
    "Now for example, if a dataset is a set of `Message` items, and the content has to be included as column, `data.content` would be the column name. If the name of the `sender` of a message has to be included, `data.sender.handle` would be a valid column name.\n",
    "\n",
    "The following example retrieves an example dataset of `Message` items, and formats them to a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081fd828",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = PodClient()\n",
    "client.add_to_schema(Dataset, DatasetEntry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b0d8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "client.add_to_schema(Account, Person, Message, CategoricalLabel, Dataset, DatasetEntry)\n",
    "\n",
    "dataset = Dataset(name=\"example-dataset\")\n",
    "\n",
    "num_items = 10\n",
    "messages = []\n",
    "items = [dataset]\n",
    "edges = []\n",
    "for i in range(num_items):\n",
    "    entry = DatasetEntry()\n",
    "    msg = Message(content=f\"content_{i}\", service=\"my_service\")\n",
    "    account = Account(handle=f\"account_{i}\")\n",
    "    person = Person(firstName=f\"firstname_{i}\")\n",
    "    label = CategoricalLabel(labelValue=f\"label_{i}\")\n",
    "    items.extend([entry, msg, account, person, label])\n",
    "    edges.extend([\n",
    "        Edge(dataset, entry, \"entry\"),\n",
    "        Edge(entry, msg, \"data\"),\n",
    "        Edge(msg, account, \"sender\"),\n",
    "        Edge(entry, label, \"annotation\"),\n",
    "        Edge(account, person, \"owner\")\n",
    "    ])\n",
    "    messages.append(msg)\n",
    "\n",
    "client.bulk_action(\n",
    "    create_items=items,\n",
    "    create_edges=edges\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d9e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = client.get_dataset(\"example-dataset\")\n",
    "\n",
    "columns = [\"data.content\", \"data.sender.handle\", \"annotation.labelValue\"]\n",
    "dataframe = dataset.to(\"pd\", columns=columns)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b9c9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "columns = [\"data.content\", \"data.sender.owner.firstName\", \"annotation.labelValue\"]\n",
    "dataframe = dataset.to(\"pd\", columns=columns)\n",
    "dataframe.head()\n",
    "\n",
    "assert isinstance(dataframe, pd.DataFrame)\n",
    "assert all(dataframe.columns == [\"id\"] + columns)\n",
    "assert len(dataframe) == num_items\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824e0b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# TODO tempfile does not work in CI\n",
    "# with tempfile.TemporaryFile(mode='w+') as f:\n",
    "#     dataset.save(f, columns=[\"content\", \"sender.owner.firstName\", \"label.name\"])\n",
    "#     f.seek(0)\n",
    "#     result = pd.read_csv(f)\n",
    "    \n",
    "# assert result.equals(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cc738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
