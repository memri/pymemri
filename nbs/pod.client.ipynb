{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp pod.client\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pod Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from pymemri.data.basic import *\n",
    "from pymemri.data.schema import *\n",
    "from pymemri.data.itembase import Edge, ItemBase, Item\n",
    "from pymemri.data.photo import Photo, NUMPY, BYTES\n",
    "from pymemri.imports import *\n",
    "from hashlib import sha256\n",
    "from pymemri.pod.db import DB\n",
    "from pymemri.pod.utils import *\n",
    "from pymemri.plugin.schema import *\n",
    "from pymemri.test_utils import get_ci_variables\n",
    "\n",
    "from typing import List, Union\n",
    "import uuid\n",
    "import urllib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "DEFAULT_POD_ADDRESS = os.environ.get(\"POD_ADDRESS\") or \"http://localhost:3030\"\n",
    "POD_VERSION = \"v4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class PodClient:\n",
    "    # Mapping from python type to schema type\n",
    "    # TODO move to data.schema once schema is refactored\n",
    "    TYPE_TO_SCHEMA = {\n",
    "        bool: \"Bool\",\n",
    "        str: \"Text\",\n",
    "        int: \"Integer\",\n",
    "        float: \"Real\",\n",
    "        datetime: \"DateTime\"       \n",
    "    }\n",
    "\n",
    "    def __init__(self, url=DEFAULT_POD_ADDRESS, version=POD_VERSION, database_key=None, owner_key=None,\n",
    "                 auth_json=None, verbose=False, register_base_schema=True):\n",
    "        self.verbose = verbose\n",
    "        self.url = url\n",
    "        self.version = POD_VERSION\n",
    "        self.test_connection(verbose=self.verbose)\n",
    "\n",
    "        self.database_key=database_key if database_key is not None else self.generate_random_key()\n",
    "        self.owner_key=owner_key if owner_key is not None else self.generate_random_key()\n",
    "        self.base_url = f\"{url}/{version}/{self.owner_key}\"\n",
    "        self.auth_json = {\"type\":\"ClientAuth\",\"databaseKey\":self.database_key} if auth_json is None \\\n",
    "                          else {**{\"type\": \"PluginAuth\"}, **auth_json}\n",
    "\n",
    "        self.local_db = DB()\n",
    "        self.registered_classes=dict()\n",
    "        self.register_base_schemas()\n",
    "        \n",
    "    @classmethod\n",
    "    def from_local_keys(cls, path=DEFAULT_POD_KEY_PATH, **kwargs):\n",
    "        return cls(database_key=read_pod_key(\"database_key\"), owner_key=read_pod_key(\"owner_key\"), **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_random_key():\n",
    "        return \"\".join([str(random.randint(0, 9)) for i in range(64)])\n",
    "    \n",
    "    def register_base_schemas(self):\n",
    "        \n",
    "        assert self.add_to_schema(\n",
    "            PluginRun, CVUStoredDefinition, Account, Photo\n",
    "        )\n",
    "\n",
    "    def test_connection(self, verbose=True):\n",
    "        try:\n",
    "            res = requests.get(self.url)\n",
    "            if verbose: print(\"Succesfully connected to pod\")\n",
    "            return True\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\"Could no connect to backend\")\n",
    "            return False\n",
    "        \n",
    "    def add_to_db(self, node):\n",
    "            existing = self.local_db.get(node.id)\n",
    "            if existing is None and node.id is not None:\n",
    "                self.local_db.add(node)\n",
    "                \n",
    "    def reset_local_db(self):\n",
    "        self.local_db = DB()\n",
    "        \n",
    "    def get_create_dict(self, node):\n",
    "        properties = node.to_json()\n",
    "        properties = {k:v for k, v in properties.items() if v != []}\n",
    "        return properties\n",
    "\n",
    "    def create(self, node):\n",
    "        create_dict = self.get_create_dict(node)\n",
    "        try:\n",
    "            body = {\"auth\": self.auth_json, \"payload\": create_dict}\n",
    "\n",
    "            result = requests.post(f\"{self.base_url}/create_item\", json=body)\n",
    "            if result.status_code != 200:\n",
    "                print(result, result.content)\n",
    "                return False\n",
    "            else:\n",
    "                id = result.json()\n",
    "                node.id = id\n",
    "                self.add_to_db(node)\n",
    "                return True\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(e)\n",
    "            return False\n",
    "        \n",
    "    def create_photo(self, photo):\n",
    "        # create the file\n",
    "        file_succes = self.create_photo_file(photo)\n",
    "        if file_succes == False:\n",
    "            raise ValueError(\"Could not create file\")\n",
    "        # create the photo\n",
    "        return self.bulk_action(create_items=[photo], create_edges=photo.get_edges(\"file\"))\n",
    "\n",
    "    \n",
    "    def _property_dicts_from_instance(self, node):\n",
    "        create_items = []\n",
    "        attributes = node.to_json()\n",
    "        for k, v in attributes.items():\n",
    "            if type(v) not in self.TYPE_TO_SCHEMA:\n",
    "                raise ValueError(f\"Could not add property {k} with type {type(v)}\")\n",
    "            value_type = self.TYPE_TO_SCHEMA[type(v)]\n",
    "\n",
    "            create_items.append({\n",
    "                \"type\": \"ItemPropertySchema\", \"itemType\": attributes[\"type\"],\n",
    "                \"propertyName\": k, \"valueType\": value_type\n",
    "            })\n",
    "        return create_items\n",
    "\n",
    "    \n",
    "    def _property_dicts_from_type(self, item):\n",
    "        create_items = []\n",
    "        for property, p_type in item.get_property_types().items():\n",
    "            p_type = self.TYPE_TO_SCHEMA[p_type]\n",
    "            create_items.append({\n",
    "                \"type\": \"ItemPropertySchema\", \"itemType\": item.__name__,\n",
    "                \"propertyName\": property, \"valueType\": p_type\n",
    "            })  \n",
    "        return create_items\n",
    "\n",
    "\n",
    "    def add_to_schema(self, *items: List[Union[object, type]]):\n",
    "        create_items = []\n",
    "\n",
    "        for item in items:\n",
    "            if isinstance(item, type):\n",
    "                property_dicts = self._property_dicts_from_type(item)\n",
    "            else:\n",
    "                property_dicts = self._property_dicts_from_instance(item)\n",
    "                item = type(item)\n",
    "            create_items.extend(property_dicts)\n",
    "            self.registered_classes[item.__name__] = item\n",
    "\n",
    "        body = {\n",
    "            \"auth\": self.auth_json, \"payload\": {\"createItems\": create_items}\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            result = requests.post(f\"{self.base_url}/bulk\", json=body)\n",
    "            if result.status_code != 200:\n",
    "                print(result, result.content)\n",
    "                return False\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(e)\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def create_photo_file(self, photo):\n",
    "        file = photo.file[0]\n",
    "        self.create(file)\n",
    "        return self._upload_image(photo.data)\n",
    "\n",
    "    def _upload_image(self, img):\n",
    "        if isinstance(img, np.ndarray):\n",
    "            return self.upload_file(img.tobytes())\n",
    "        elif isinstance(img, bytes):\n",
    "            return self.upload_file(img)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown image data type {type(img)}\")\n",
    "\n",
    "    def upload_file(self, file):\n",
    "        # TODO: currently this only works for numpy images\n",
    "        if self.auth_json.get(\"type\") == \"PluginAuth\":\n",
    "            # alternative file upload for plugins, with different authentication\n",
    "            return self.upload_file_b(file)\n",
    "        else:\n",
    "            try:\n",
    "                sha = sha256(file).hexdigest()\n",
    "                result = requests.post(f\"{self.base_url}/upload_file/{self.database_key}/{sha}\", data=file)\n",
    "                if result.status_code in [200, 409]: # 409 = CONFLICT, file already exists\n",
    "                    return True\n",
    "                else:\n",
    "                    print(result, result.content)\n",
    "                    return False\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(e)\n",
    "                return False\n",
    "            \n",
    "    def upload_file_b(self, file):\n",
    "        try:\n",
    "            sha = sha256(file).hexdigest()\n",
    "            auth = urllib.parse.quote(json.dumps(self.auth_json))\n",
    "            result = requests.post(f\"{self.base_url}/upload_file_b/{auth}/{sha}\", data=file)\n",
    "            if result.status_code in [200, 409]: # 409 = CONFLICT, file already exists\n",
    "                return True\n",
    "            else:\n",
    "                print(result, result.content)\n",
    "                return False\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(e)\n",
    "            return False        \n",
    "\n",
    "    def get_file(self, sha):\n",
    "        # TODO: currently this only works for numpy images\n",
    "        try:\n",
    "            body= {\"auth\": self.auth_json,\n",
    "                   \"payload\": {\"sha256\": sha}}\n",
    "            result = requests.post(f\"{self.base_url}/get_file\", json=body)\n",
    "            if result.status_code != 200:\n",
    "                print(result, result.content)\n",
    "                return None\n",
    "            else:\n",
    "                return result.content\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(e)\n",
    "            return None\n",
    "\n",
    "    def get_photo(self, id, size=640):\n",
    "        photo = self.get(id)\n",
    "        self._load_photo_data(photo, size=size)\n",
    "        return photo\n",
    "\n",
    "    def _load_photo_data(self, photo, size=None):\n",
    "        if len(photo.file) > 0 and photo.data is None:\n",
    "            file = self.get_file(photo.file[0].sha256)\n",
    "            if file is None:\n",
    "                print(f\"Could not load data of {photo} attached file item does not have data in pod\")\n",
    "                return\n",
    "            if photo.encoding == NUMPY:\n",
    "                data = np.frombuffer(file, dtype=np.uint8)\n",
    "                c = photo.channels\n",
    "                shape = (photo.height,photo.width, c) if c is not None and c > 1 else (photo.height, photo.width)\n",
    "                data = data.reshape(shape)\n",
    "                if size is not None: data = resize(data, size)\n",
    "                photo.data = data\n",
    "                return\n",
    "            elif photo.encoding == BYTES:\n",
    "                photo.data = file\n",
    "                return\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported encoding\")\n",
    "        print(f\"could not load data of {photo}, no file attached\")\n",
    "\n",
    "    def create_if_external_id_not_exists(self, node):\n",
    "        if not self.external_id_exists(node):\n",
    "            self.create(node)\n",
    "\n",
    "    def external_id_exists(self, node):\n",
    "        if node.externalId is None: return False\n",
    "        existing = self.search({\"externalId\": node.externalId})\n",
    "        return len(existing) > 0\n",
    "\n",
    "    def create_edges(self, edges):\n",
    "        \"\"\"Create edges between nodes, edges should be of format:\n",
    "           [{\"_type\": \"friend\", \"_source\": 1, \"_target\": 2}]\"\"\"\n",
    "        return self.bulk_action(create_edges=edges)\n",
    "\n",
    "#         create_edges = []\n",
    "#         for e in edges:\n",
    "#             src, target = e.source.id, e.target.id\n",
    "\n",
    "#             if src is None or target is None:\n",
    "#                 print(f\"Could not create edge {e} missing source or target id\")\n",
    "#                 return False\n",
    "#             data = {\"_source\": src, \"_target\": target, \"_name\": e._type}\n",
    "#             if e.label is not None: data[LABEL] = e.label\n",
    "#             if e.sequence is not None: data[SEQUENCE] = e.sequence\n",
    "\n",
    "#             if e.reverse:\n",
    "#                 data2 = copy(data)\n",
    "#                 data2[\"_source\"] = target\n",
    "#                 data2[\"_target\"] = src\n",
    "#                 data2[\"_name\"] = \"~\" + data2[\"_name\"]\n",
    "#                 create_edges.append(data2)\n",
    "\n",
    "#             create_edges.append(data)\n",
    "\n",
    "#         return self.bulk_action(create_items=[], update_items=[],create_edges=create_edges)\n",
    "\n",
    "    def delete_items(self, items):\n",
    "        return self.bulk_action(delete_items=items) \n",
    "\n",
    "    def delete_all(self):\n",
    "        items = self.get_all_items()\n",
    "        self.delete_items(items)\n",
    "        \n",
    "    @staticmethod\n",
    "    def gather_batch(items, start_idx, start_size=0, max_size=5000000):\n",
    "        idx = start_idx\n",
    "        total_size = start_size\n",
    "        batch_items = []\n",
    "        for i, x in enumerate(items):\n",
    "            if i < idx:\n",
    "                continue\n",
    "            elif len(str(x)) > max_size:\n",
    "                idx = i + 1\n",
    "                print(\"Could not add item: Item exceeds max item size\")\n",
    "            elif total_size + len(str(x)) < max_size:\n",
    "                batch_items.append(x)\n",
    "                total_size += len(str(x))\n",
    "                idx = i + 1\n",
    "            else:\n",
    "                break\n",
    "        return batch_items, idx, total_size\n",
    "    \n",
    "    def bulk_action(self, create_items=None, update_items=None, create_edges=None, delete_items=None):\n",
    "        # we need to set the id to not lose the reference\n",
    "        if create_items is not None:\n",
    "            for c in create_items:\n",
    "                if c.id is None: c.id = uuid.uuid4().hex\n",
    "        create_items = [self.get_create_dict(i) for i in create_items] if create_items is not None else []\n",
    "        update_items = [self.get_update_dict(i) for i in update_items] if update_items is not None else []\n",
    "        create_edges = [self.get_create_edge_dict(i) for i in create_edges] if create_edges is not None else []\n",
    "        # Note: skip delete_items without id, as items that are not in pod cannot be deleted\n",
    "        delete_items = [item.id for item in delete_items if item.id is not None] if delete_items is not None else []\n",
    "        \n",
    "        n_total = len(create_items + update_items + create_edges + delete_items)        \n",
    "        n=0\n",
    "        \n",
    "        i_ci, i_ui, i_ce, i_di = 0,0,0,0\n",
    "        while not( i_ci == len(create_items) and i_ui == len(update_items) and i_ce == len(create_edges) and i_di == len(delete_items)):\n",
    "            batch_size=0\n",
    "            create_items_batch, i_ci, batch_size = self.gather_batch(create_items, i_ci, start_size=batch_size)\n",
    "            update_items_batch, i_ui, batch_size = self.gather_batch(update_items, i_ui, start_size=batch_size)\n",
    "            delete_items_batch, i_di, batch_size = self.gather_batch(delete_items, i_di, start_size=batch_size)\n",
    "            if i_ci == len(create_items): \n",
    "                create_edges_batch, i_ce, batch_size = self.gather_batch(create_edges, i_ce, start_size=batch_size)\n",
    "            else:\n",
    "                create_edges_batch = []\n",
    "            n_batch = len(create_items_batch+update_items_batch+create_edges_batch+delete_items_batch)\n",
    "            n+=n_batch\n",
    "            print(f\"BULK: Writing {n}/{n_total} items/edges\")\n",
    "            succes = self._bulk_action(create_items_batch, update_items_batch, create_edges_batch, delete_items_batch)\n",
    "            if not succes:\n",
    "                print(\"could not complete bulk aciton, aborting\")\n",
    "                return False\n",
    "        print(f\"Completed Bulk action, written {n} items/edges\")\n",
    "        return True\n",
    "\n",
    "    def _bulk_action(self, create_items=None, update_items=None, create_edges=None, delete_items=None):\n",
    "        json_data = {\n",
    "            \"auth\": self.auth_json,\n",
    "            \"payload\": {\n",
    "                \"createItems\": create_items, \"updateItems\": update_items,\n",
    "                \"createEdges\": create_edges, \"deleteItems\": delete_items\n",
    "            }\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            result = requests.post(f\"{self.base_url}/bulk\",\n",
    "                                   json=json_data)\n",
    "            if result.status_code != 200:\n",
    "                if \"UNIQUE constraint failed\" in str(result.content):\n",
    "                    print(result.status_code, result.content, \"Failed bulk update\")\n",
    "                else:\n",
    "                    print(result, result.content)\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(e)\n",
    "            return False\n",
    "\n",
    "    def get_create_edge_dict(self, edge):\n",
    "        return {\"_source\": edge.source.id, \"_target\": edge.target.id, \"_name\": edge._type}\n",
    "        \n",
    "    def create_edge(self, edge):\n",
    "        payload = self.get_create_edge_dict(edge)\n",
    "        body = {\"auth\": self.auth_json,\n",
    "                \"payload\": payload}\n",
    "\n",
    "        try:\n",
    "            result = requests.post(f\"{self.base_url}/create_edge\", json=body)\n",
    "            if result.status_code != 200:\n",
    "                print(result, result.content)\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(e)\n",
    "            return False\n",
    "\n",
    "        return self.create_edges([edge])\n",
    "\n",
    "    def get(self, id, expanded=True):\n",
    "        if not expanded:\n",
    "            res = self._get_item_with_properties(id)\n",
    "        else:\n",
    "            res = self._get_item_expanded(id)\n",
    "        if res is None:\n",
    "            raise ValueError(f\"Item with id {id} does not exist\")\n",
    "\n",
    "        elif res.deleted == True:\n",
    "            print(f\"Item with id {id} does not exist anymore\")\n",
    "            return None\n",
    "        else:\n",
    "            return res\n",
    "\n",
    "    def get_all_items(self):\n",
    "        raise NotImplementedError()\n",
    "        try:\n",
    "            body = {  \"databaseKey\": self.database_key, \"payload\":None}\n",
    "            result = requests.post(f\"{self.base_url}/get_all_items\", json=body)\n",
    "            if result.status_code != 200:\n",
    "                print(result, result.content)\n",
    "                return None\n",
    "            else:\n",
    "                json = result.json()\n",
    "                res =  [self.item_from_json(x) for x in json]\n",
    "                return self.filter_deleted(res)\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(e)\n",
    "            return None\n",
    "\n",
    "    def filter_deleted(self, items):\n",
    "        return [i for i in items if not i.deleted == True]\n",
    "\n",
    "    def _get_item_expanded(self, id):\n",
    "        item = self.get(id, expanded=False)\n",
    "        edges = self.get_edges(id)\n",
    "        for e in edges:\n",
    "            item.add_edge(e[\"name\"], e[\"item\"])\n",
    "        return item\n",
    "\n",
    "    def get_edges(self, id):\n",
    "        body = {\"payload\": {\"item\": str(id),\n",
    "                            \"direction\": \"Outgoing\",\n",
    "                            \"expandItems\": True},\n",
    "                \"auth\": self.auth_json}\n",
    "\n",
    "        try:\n",
    "            result = requests.post(f\"{self.base_url}/get_edges\", json=body)\n",
    "            if result.status_code != 200:\n",
    "                print(result, result.content)\n",
    "                return None\n",
    "            else:\n",
    "                json = result.json()\n",
    "                for d in json:\n",
    "                    d[\"item\"] = self.item_from_json(d[\"item\"])\n",
    "                return json\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(e)\n",
    "            return None\n",
    "\n",
    "    def _get_item_with_properties(self, id):\n",
    "        try:\n",
    "            body = {\"auth\": self.auth_json,\n",
    "                    \"payload\": str(id)}\n",
    "            result = requests.post(f\"{self.base_url}/get_item\", json=body)\n",
    "            if result.status_code != 200:\n",
    "                print(result, result.content)\n",
    "                return None\n",
    "            else:\n",
    "                json = result.json()\n",
    "                if json == []:\n",
    "                    return None\n",
    "                else:\n",
    "                    res =  self.item_from_json(json[0])\n",
    "                    return res\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(e)\n",
    "            return None\n",
    "            \n",
    "    def get_update_dict(self, node):\n",
    "        properties = node.to_json(dates=False)\n",
    "        properties.pop(\"type\", None)\n",
    "        properties.pop(\"deleted\", None)\n",
    "        return properties\n",
    "    \n",
    "    def update_item(self, node):\n",
    "        data = self.get_update_dict(node)\n",
    "        body = {\"payload\": data,\n",
    "                \"auth\": self.auth_json}\n",
    "        try:\n",
    "            result = requests.post(f\"{self.base_url}/update_item\",\n",
    "                                  json=body)\n",
    "            if result.status_code != 200:\n",
    "                print(result, result.content)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(e)\n",
    "            \n",
    "    def exists(self, id):\n",
    "        try:\n",
    "            body = {\"auth\": self.auth_json,\n",
    "                    \"payload\": str(id)}\n",
    "            result = requests.post(f\"{self.base_url}/get_item\", json=body)\n",
    "            if result.status_code != 200:\n",
    "                print(result, result.content)\n",
    "                return False\n",
    "            else:\n",
    "                json = result.json()\n",
    "                if isinstance(json, list) and len(json) > 0:\n",
    "                    return True\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(e)\n",
    "            return None\n",
    "\n",
    "    def search_paginate(self, fields_data, limit=50):\n",
    "        \"\"\"\n",
    "        A generator that performs search with pagination.\n",
    "        \n",
    "        Returns at least `limit` items, but can return more because\n",
    "        of pod implementation details.\n",
    "        \"\"\"\n",
    "        if (\n",
    "            \"_limit\" in fields_data\n",
    "            or \"dateServerModified\" in fields_data\n",
    "            or \"dateServerModified>=\" in fields_data\n",
    "            or \"dateServerModified<\" in fields_data\n",
    "        ):\n",
    "            raise ValueError(\"Cannot paginate query\")\n",
    "        if \"_sortOrder\" in fields_data:\n",
    "            raise NotImplementedError(\"Only 'Asc' order is supported.\")\n",
    "\n",
    "        response = self.search({**fields_data, \"_limit\": limit})\n",
    "        next_dsm = int(response[-1].dateServerModified.timestamp() * 1000) + 1\n",
    "        yield response\n",
    "\n",
    "        while True:\n",
    "            response = client.search(\n",
    "                {**fields_data, \"_limit\": limit, \"dateServerModified>=\": next_dsm}\n",
    "            )\n",
    "            if not len(response):\n",
    "                break\n",
    "            next_dsm = int(response[-1].dateServerModified.timestamp() * 1000) + 1\n",
    "            yield response\n",
    "\n",
    "    def search(self, fields_data, include_edges: bool = True):\n",
    "        extra_fields = {'[[edges]]': {}} if include_edges else {}\n",
    "        body = {\"payload\": {**fields_data, **extra_fields},\n",
    "                \"auth\": self.auth_json}\n",
    "        try:\n",
    "            result = requests.post(f\"{self.base_url}/search\", json=body)\n",
    "            json =  result.json()\n",
    "\n",
    "            res = [self._item_from_search(item) for item in json]\n",
    "            return self.filter_deleted(res)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return None\n",
    "\n",
    "\n",
    "    def _item_from_search(self, item_json: dict):\n",
    "        # search returns different fields w.r.t. edges compared to `get` api,\n",
    "        # different method to keep `self.get` clean.\n",
    "        item = self.item_from_json(item_json)\n",
    "\n",
    "        for edge_json in item_json.get(\"[[edges]]\", []):\n",
    "            edge_name = edge_json[\"_edge\"]\n",
    "            try:\n",
    "                edge_item = self.item_from_json(edge_json[\"_item\"])\n",
    "                item.add_edge(edge_name, edge_item)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        return item\n",
    "\n",
    "    def search_last_added(self, type=None, with_prop=None, with_val=None):\n",
    "        query = {\"_limit\": 1, \"_sortOrder\": \"Desc\"}\n",
    "        if type is not None:\n",
    "            query[\"type\"] = type\n",
    "        if with_prop is not None:\n",
    "            query[f\"{with_prop}==\"] = with_val\n",
    "\n",
    "        return self.search(query)[0]\n",
    "\n",
    "    def item_from_json(self, json):\n",
    "        plugin_class = json.get(\"pluginClass\", None)\n",
    "        plugin_package = json.get(\"pluginPackage\", None)\n",
    "\n",
    "        constructor = get_constructor(json[\"type\"], plugin_class, plugin_package=plugin_package,\n",
    "                                      extra=self.registered_classes)\n",
    "        new_item = constructor.from_json(json)\n",
    "        existing = self.local_db.get(new_item.id)\n",
    "        # TODO: cleanup\n",
    "        if existing is not None:\n",
    "            if not existing.is_expanded() and new_item.is_expanded():\n",
    "                for edge_name in new_item.get_all_edge_names():\n",
    "                    edges = new_item.get_edges(edge_name)\n",
    "                    for e in edges:\n",
    "                        e.source = existing\n",
    "                    existing.__setattr__(edge_name, edges)\n",
    "\n",
    "            for prop_name in new_item.get_property_names():\n",
    "                existing.__setattr__(prop_name, new_item.__getattribute__(prop_name))\n",
    "            return existing\n",
    "        else:\n",
    "            return new_item\n",
    "\n",
    "    def get_properties(self, expanded):\n",
    "        properties = copy(expanded)\n",
    "        if ALL_EDGES in properties: del properties[ALL_EDGES]\n",
    "        return properties\n",
    "    \n",
    "    def send_email(self, to, subject=\"\", body=\"\"):\n",
    "        body = {\"payload\": {\"to\": to,\n",
    "                            \"subject\": subject,\n",
    "                            \"body\": body\n",
    "                           },\n",
    "                \"auth\": self.auth_json}\n",
    "        try:\n",
    "            result = requests.post(f\"{self.base_url}/send_email\", json=body)\n",
    "            if result.status_code == 200:\n",
    "                print(f\"succesfully sent email to {to}\")\n",
    "            else:\n",
    "                print(f\"could not send email {result.content}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(e)\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pymemri communicates with the pod via the `PodClient`. The PodClient requires you to provide a [database key](https://gitlab.memri.io/memri/pod/-/blob/dev/docs/HTTP_API.md#user-content-api-authentication-credentials) and an [owner key](https://gitlab.memri.io/memri/pod/-/blob/dev/docs/HTTP_API.md#user-content-api-authentication-credentials). During development, you don't have to worry about these keys, you can just omit the keys when initializing the `PodClient`, which creates a new user by defining random keys. *Note that this will create a new database for your every time you create a PodClient, if you want to access the same database with multiple PodClients, you have to set the  same keys* When you are using the app, setting the keys in the pod, and passing them when calling an integrator is handled for you by the app itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully connected to pod\n"
     ]
    }
   ],
   "source": [
    "client = PodClient()\n",
    "success = client.test_connection()\n",
    "assert success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Items and Edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have access to the pod, we can create items here and upload them to the pod. All items are defined in the schema of the pod. To create an item in the pod, you have to add the schema first. Schemas can be added as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymemri.data.schema import EmailMessage, Address, PhoneNumber\n",
    "\n",
    "succes = client.add_to_schema(EmailMessage, Address, PhoneNumber)\n",
    "assert succes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create our item. As a side-effect, our item will be assigned an id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_item = EmailMessage.from_data(content=\"example content field\")\n",
    "client.create(email_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e1c9f75fd6e46f4bb43cb6c6d00f4fe9'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_item.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily define our own types, and use them in the pod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Dog(Item):\n",
    "    properties = Item.properties + [\"name\", \"age\", \"bites\", \"weight\"]\n",
    "    edges = Item.edges \n",
    "    def __init__(self, name: str=None, age: int=None, bites: bool=False, weight: float=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "        self.bites = bites\n",
    "        self.weight = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog = Dog(\"\", 0, True, 0.)\n",
    "client.add_to_schema(dog)\n",
    "dog2 = Dog(name=\"bob\", age=3, weight=33.2)\n",
    "client.create(dog2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.reset_local_db()\n",
    "dog_from_db = client.get(dog2.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dog_from_db.name == \"bob\"\n",
    "assert dog_from_db.age == 3\n",
    "assert dog_from_db.weight == 33.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can connect items using edges. Let's create another item, a person, and connect the email and the person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_item = Person.from_data(firstName=\"Alice\", lastName=\"X\")\n",
    "succes = client.add_to_schema(person_item)\n",
    "assert succes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_item = Person.from_data(firstName=\"Alice\", lastName=\"X\")\n",
    "item_succes = client.create(person_item)\n",
    "edge = Edge(email_item, person_item, \"sender\")\n",
    "edge_succes = client.create_edge(edge)\n",
    "assert item_succes\n",
    "assert edge_succes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'item': Person (#988e4015b1add71cf04ed7ad8d849632), 'name': 'sender'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_edges(email_item.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use the normal `client.get` (without `expanded=False`), we also get items directly connected to the Item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_from_db = client.get(email_item.id) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(email_from_db.sender[0], Person)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching and updating Items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the client to fetch data from the database. This is in particular useful for indexers, which often use data in the database as input for their models. The simplest form  of querying the database is by querying items in the pod by their id (unique identifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_item = Person.from_data(firstName=\"Alice\")\n",
    "assert client.create(person_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_from_db = client.get(person_item.id, expanded=False)\n",
    "assert person_from_db is not None\n",
    "assert person_from_db == person_item\n",
    "assert person_from_db.id is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appart from creating, we might want to update existing items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_item.lastName = \"Awesome\"\n",
    "client.update_item(person_item)\n",
    "person_from_db = client.get(person_item.id, expanded=False)\n",
    "assert person_from_db.lastName == \"Awesome\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we don't know the ids of the items we want to fetch, we can also search by property. We can use this for instance when we want to query all items from a particular type to perform some indexing on. We can get all `Person` Items from the db by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BULK: Writing 1/1 items/edges\n",
      "Completed Bulk action, written 1 items/edges\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_item2 = Person.from_data(firstName=\"Bob\")\n",
    "person_account = Account(service=\"testService\")\n",
    "client.create(person_item2)\n",
    "client.create(person_account)\n",
    "\n",
    "person_item2.add_edge(\"account\", person_account)\n",
    "client.create_edges(person_item2.get_edges(\"account\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search without edges\n",
    "\n",
    "# To test search with and without include_edges, make a fresh client (no local_db)\n",
    "new_client = PodClient(owner_key=client.owner_key, database_key=client.database_key)\n",
    "\n",
    "all_people = new_client.search({\"type\": \"Person\"}, include_edges=False)\n",
    "assert all([isinstance(p, Person) for p in all_people]) and len(all_people) > 0\n",
    "assert all([len(p.account)==0 for p in all_people])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search with edges\n",
    "\n",
    "all_people = new_client.search({\"type\": \"Person\"}, include_edges=True)\n",
    "assert all([isinstance(p, Person) for p in all_people]) and len(all_people) > 0\n",
    "assert any([len(p.account) for p in all_people])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search with pagination\n",
    "\n",
    "for i in range(10):\n",
    "    client.bulk_action(create_items=[\n",
    "        Account(identifier=f\"{j + i*10}\", service=\"paginate_test\") for j in range(10)\n",
    "    ])\n",
    "\n",
    "accounts = client.search({\"type\": \"Account\", \"service\": \"paginate_test\"})\n",
    "\n",
    "generator = client.search_paginate({\"type\": \"Account\", \"service\": \"paginate_test\"})\n",
    "accounts_paginated = []\n",
    "for page in generator:\n",
    "    accounts_paginated.extend(page)\n",
    "    \n",
    "assert len(accounts_paginated) == 100\n",
    "assert [a.id for a in accounts] == [a.id for a in accounts_paginated]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search last added items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_item2 = Person.from_data(firstName=\"Last Person\")\n",
    "client.create(person_item2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert client.search_last_added(type=\"Person\").firstName == \"Last Person\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the near future, Pod will support searching by user defined properties as well. This will allow for the following. **warning, this is currently not supported**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```client.search_last_added(type=\"Person\", with_prop=\"ImportedBy\", with_val=\"EmailImporter\")```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading & downloading files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with files, the `PodClient` has a file api. The file api works by posting a blob to the `upload_file` endpoint, and creating an Item with a property with the same sha256 as the sha used in the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymemri.data.photo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randint(0, 255+1, size=(640, 640), dtype=np.uint8)\n",
    "photo = Photo.from_np(x)\n",
    "file = photo.file[0]\n",
    "succes = client.create(file)\n",
    "succes2 = client._upload_image(x)\n",
    "assert succes\n",
    "assert succes2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = client.get_file(file.sha256)\n",
    "arr = np.frombuffer(data, dtype=np.uint8)\n",
    "assert (arr.reshape(640,640) == x).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Photo API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For photos we do this automatically using `PodClient.create` on a Photo and `PodClient.get_photo`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randint(0, 255+1, size=(640, 640), dtype=np.uint8)\n",
    "photo = Photo.from_np(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "succes = client.add_to_schema(Photo.from_np(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BULK: Writing 2/2 items/edges\n",
      "Completed Bulk action, written 2 items/edges\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_photo(photo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.get_photo(photo.id, size=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (res.data == x).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some photos come as bytes, we can use `Iphoto.from_bytes` to initialize those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_bytes = b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\xe1\\x00\\x00\\x00\\xe1\\x08\\x03\\x00\\x00\\x00\\tm\"H\\x00\\x00\\x003PLTE\\x04\\x02\\x04\\x00\\x00\\x00\\xa0\\xa0\\xa0\\xa3\\xa3\\xa3\\xaa\\xaa\\xaa\\xb4\\xb4\\xb4\\xbd\\xbe\\xbd\\xbb\\xbc\\xbb\\xde\\xde\\xde\\x9b\\x9a\\x9b\\xfe\\xfe\\xfe\\xf2\\xf3\\xf2\\xe5\\xe6\\xe5\\xd8\\xd9\\xd8\\xd1\\xd1\\xd1\\xc9\\xca\\xc9\\xae\\xae\\xae\\x80k\\x98\\xfc\\x00\\x00\\x01TIDATx\\x9c\\xed\\xdd;r\\xc2P\\x00\\x04A!\\x90\\x84\\xfc\\x01\\xee\\x7fZ\\x138\\xb1\\x13S\\xceF\\xaf\\xfb\\x06\\x93o\\xd5No\\xef\\x1f\\x9f\\xb7\\xfb}]\\xd7my\\xba|;\\xff4\\xff\\xdf\\xf9O\\x97W<\\x96W\\xac\\xbfm\\xd7i9\\x1d\\xdb\\xfe,\\x9c\\x8e\\xec4+\\xac{\\x16^\\x14\\xb6)\\xecS\\xd8\\xa7\\xb0Oa\\x9f\\xc2\\xbe!\\n\\xcf\\n\\xdb\\x14\\xf6)\\xecS\\xd8\\xa7\\xb0Oa\\x9f\\xc2>\\x85}\\n\\xfb\\x14\\xf6)\\xecS\\xd8\\xa7\\xb0Oa\\x9f\\xc2>\\x85}C\\x14\\xce\\n\\xdb\\x14\\xf6)\\xecS\\xd8\\xa7\\xb0Oa\\x9f\\xc2>\\x85}\\n\\xfb\\x14\\xf6)\\xecS\\xd8\\xa7\\xb0Oa\\x9f\\xc2>\\x85}\\n\\xfb\\x14\\xf6)\\xecS\\xd87\\xc4bHa\\x9c\\xc2>\\x85}\\n\\xfb\\x14\\xf6)\\xecS\\xd8\\xa7\\xb0Oa\\x9f\\xc2>\\x85}\\n\\xfb\\x14\\xf6)\\xecS\\xd8\\xa7\\xb0Oa\\x9f\\xc2>\\x85}\\n\\xfb\\x86xaQ\\x18\\xa7\\xb0Oa\\x9f\\xc2>\\x85}\\n\\xfb\\x14\\xf6)\\xecS\\xd8\\xa7\\xb0Oa\\x9f\\xc2>\\x85}\\n\\xfb\\x14\\xf6)\\xecS\\xd87D\\xe1\\xe3\\xf0\\x85\\x8b\\xc26\\x85}\\n\\xfb\\x14\\xf6)\\xecS\\xd8\\xa7\\xb0Oa\\x9f\\xc2>\\x85}\\n\\xfb\\x14\\xf6)\\xecS\\xd8\\xa7\\xb0Oa\\x9f\\xc2>\\x85}C\\x14\\xae\\n\\xdb\\x14\\xf6)\\xecS\\xd8\\xa7\\xb0Oa\\x9f\\xc2>\\x85}C\\x14n\\xa7c\\xdb\\xa7\\xeb>\\x1f\\xd9~\\xfb\\x02\\xee\\x7f\\r\\xe5\\xe1h\\x04\"\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo = Photo.from_bytes(_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BULK: Writing 2/2 items/edges\n",
      "Completed Bulk action, written 2 items/edges\n"
     ]
    }
   ],
   "source": [
    "assert client.create_photo(photo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new client to prevent caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_client = PodClient(database_key=client.database_key, owner_key=client.owner_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = new_client.get_photo(photo.id, size=225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.data == photo.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[File (#f97f96d594a36ba33bbece3dba8a62ac)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulk API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, an api call takes a lot of time (~0.1 second). If you want to write many data items to the pod, you can use the bulk api for efficiency reasons. Currently, only creating `Items` and `Edges` is supported, support for updating and deletion will follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BULK: Writing 495/503 items/edges\n",
      "BULK: Writing 503/503 items/edges\n",
      "Completed Bulk action, written 503 items/edges\n"
     ]
    }
   ],
   "source": [
    "# Test bulk create items and edges\n",
    "\n",
    "dogs = [Dog(name=f\"dog number {i} \" +\"a\" * 10000) for i in range(500)]\n",
    "person = Person(firstName=\"Alice\")\n",
    "edge1 = Edge(dogs[0], person, \"label\")\n",
    "edge2 = Edge(dogs[1], person, \"label\")\n",
    "\n",
    "client.bulk_action(create_items=dogs + [person], create_edges=[edge1,edge2])\n",
    "\n",
    "dogs_with_edge = [item for item in client.search({\"type\": \"Dog\"}) if item.name.startswith(\"dog number 0\")\n",
    "                  or item.name.startswith(\"dog number 1 \")]\n",
    "\n",
    "assert len(dogs_with_edge) == 2\n",
    "for d in dogs_with_edge:\n",
    "    assert len(d.label) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BULK: Writing 2/2 items/edges\n",
      "Completed Bulk action, written 2 items/edges\n"
     ]
    }
   ],
   "source": [
    " # test bulk delete and update\n",
    "\n",
    "# Change person name, delete first dog :(\n",
    "person.firstName = \"Bob\"\n",
    "to_delete = [dogs[0]]\n",
    "to_update = [person]\n",
    "\n",
    "client.bulk_action(delete_items=to_delete, update_items=to_update)\n",
    "dogs_with_edge = [\n",
    "    item for item in client.search({\"type\": \"Dog\"}) if item.name.startswith(\"dog number 0\") or item.name.startswith(\"dog number 1 \")\n",
    "]\n",
    "\n",
    "assert len(dogs_with_edge) == 1\n",
    "\n",
    "dog = dogs_with_edge[0]\n",
    "assert dog.label[0].firstName == \"Bob\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sending emails -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    to = \"myemail@gmail.com\"\n",
    "    client.send_email(to=to, subject=\"test\", body=\"test2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if an item exists -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# person_item = Person.from_data(firstName=\"Eve\",   externalId=\"gmail_1\")\n",
    "# person_item2 = Person.from_data(firstName=\"Eve2\", externalId=\"gmail_1\")\n",
    "\n",
    "# client.create_if_external_id_not_exists(person_item)\n",
    "# client.create_if_external_id_not_exists(person_item2)\n",
    "\n",
    "# existing = client.search({\"externalId\": \"gmail_1\"})\n",
    "# assert len(existing) == 1\n",
    "# client.delete_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resetting the db -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.delete_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Untitled.ipynb.\n",
      "Converted basic.ipynb.\n",
      "Converted cvu.utils.ipynb.\n",
      "Converted data.photo.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted itembase.ipynb.\n",
      "Converted plugin.authenticators.credentials.ipynb.\n",
      "Converted plugin.authenticators.oauth.ipynb.\n",
      "Converted plugin.ipynb.\n",
      "Converted plugin.pluginbase.ipynb.\n",
      "Converted plugin.states.ipynb.\n",
      "Converted plugins.authenticators.password.ipynb.\n",
      "Converted pod.client.ipynb.\n",
      "Converted pod.db.ipynb.\n",
      "Converted pod.utils.ipynb.\n",
      "Converted test_schema.ipynb.\n",
      "Converted test_utils.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
